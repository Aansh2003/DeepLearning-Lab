{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b83a139-4e1a-429d-bc69-011a9227a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4699baf5-1393-4360-8180-f76ea82f7aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density</th>\n",
       "      <th>BodyFat</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0708</td>\n",
       "      <td>12.3</td>\n",
       "      <td>23</td>\n",
       "      <td>154.25</td>\n",
       "      <td>67.75</td>\n",
       "      <td>36.2</td>\n",
       "      <td>93.1</td>\n",
       "      <td>85.2</td>\n",
       "      <td>94.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0853</td>\n",
       "      <td>6.1</td>\n",
       "      <td>22</td>\n",
       "      <td>173.25</td>\n",
       "      <td>72.25</td>\n",
       "      <td>38.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>37.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0414</td>\n",
       "      <td>25.3</td>\n",
       "      <td>22</td>\n",
       "      <td>154.00</td>\n",
       "      <td>66.25</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>99.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>38.9</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0751</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26</td>\n",
       "      <td>184.75</td>\n",
       "      <td>72.25</td>\n",
       "      <td>37.4</td>\n",
       "      <td>101.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>101.2</td>\n",
       "      <td>60.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>32.4</td>\n",
       "      <td>29.4</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0340</td>\n",
       "      <td>28.7</td>\n",
       "      <td>24</td>\n",
       "      <td>184.25</td>\n",
       "      <td>71.25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>97.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.9</td>\n",
       "      <td>63.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.0736</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>134.25</td>\n",
       "      <td>67.00</td>\n",
       "      <td>34.9</td>\n",
       "      <td>89.2</td>\n",
       "      <td>83.6</td>\n",
       "      <td>88.8</td>\n",
       "      <td>49.6</td>\n",
       "      <td>34.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.7</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.0236</td>\n",
       "      <td>33.6</td>\n",
       "      <td>72</td>\n",
       "      <td>201.00</td>\n",
       "      <td>69.75</td>\n",
       "      <td>40.9</td>\n",
       "      <td>108.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>104.5</td>\n",
       "      <td>59.6</td>\n",
       "      <td>40.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>28.6</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1.0328</td>\n",
       "      <td>29.3</td>\n",
       "      <td>72</td>\n",
       "      <td>186.75</td>\n",
       "      <td>66.00</td>\n",
       "      <td>38.9</td>\n",
       "      <td>111.1</td>\n",
       "      <td>111.5</td>\n",
       "      <td>101.7</td>\n",
       "      <td>60.3</td>\n",
       "      <td>37.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>31.3</td>\n",
       "      <td>27.2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.0399</td>\n",
       "      <td>26.0</td>\n",
       "      <td>72</td>\n",
       "      <td>190.75</td>\n",
       "      <td>70.50</td>\n",
       "      <td>38.9</td>\n",
       "      <td>108.3</td>\n",
       "      <td>101.3</td>\n",
       "      <td>97.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>30.5</td>\n",
       "      <td>29.4</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.0271</td>\n",
       "      <td>31.9</td>\n",
       "      <td>74</td>\n",
       "      <td>207.50</td>\n",
       "      <td>70.00</td>\n",
       "      <td>40.8</td>\n",
       "      <td>112.4</td>\n",
       "      <td>108.5</td>\n",
       "      <td>107.1</td>\n",
       "      <td>59.3</td>\n",
       "      <td>42.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen    Hip  \\\n",
       "0     1.0708     12.3   23  154.25   67.75  36.2   93.1     85.2   94.5   \n",
       "1     1.0853      6.1   22  173.25   72.25  38.5   93.6     83.0   98.7   \n",
       "2     1.0414     25.3   22  154.00   66.25  34.0   95.8     87.9   99.2   \n",
       "3     1.0751     10.4   26  184.75   72.25  37.4  101.8     86.4  101.2   \n",
       "4     1.0340     28.7   24  184.25   71.25  34.4   97.3    100.0  101.9   \n",
       "..       ...      ...  ...     ...     ...   ...    ...      ...    ...   \n",
       "247   1.0736     11.0   70  134.25   67.00  34.9   89.2     83.6   88.8   \n",
       "248   1.0236     33.6   72  201.00   69.75  40.9  108.5    105.0  104.5   \n",
       "249   1.0328     29.3   72  186.75   66.00  38.9  111.1    111.5  101.7   \n",
       "250   1.0399     26.0   72  190.75   70.50  38.9  108.3    101.3   97.8   \n",
       "251   1.0271     31.9   74  207.50   70.00  40.8  112.4    108.5  107.1   \n",
       "\n",
       "     Thigh  Knee  Ankle  Biceps  Forearm  Wrist  \n",
       "0     59.0  37.3   21.9    32.0     27.4   17.1  \n",
       "1     58.7  37.3   23.4    30.5     28.9   18.2  \n",
       "2     59.6  38.9   24.0    28.8     25.2   16.6  \n",
       "3     60.1  37.3   22.8    32.4     29.4   18.2  \n",
       "4     63.2  42.2   24.0    32.2     27.7   17.7  \n",
       "..     ...   ...    ...     ...      ...    ...  \n",
       "247   49.6  34.8   21.5    25.6     25.7   18.5  \n",
       "248   59.6  40.8   23.2    35.2     28.6   20.1  \n",
       "249   60.3  37.3   21.5    31.3     27.2   18.0  \n",
       "250   56.0  41.6   22.7    30.5     29.4   19.8  \n",
       "251   59.3  42.2   24.6    33.7     30.0   20.9  \n",
       "\n",
       "[252 rows x 15 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bodyfat.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a981279-7ae8-415f-ac84-e5593ac02dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Density</th>\n",
       "      <th>BodyFat</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965642</td>\n",
       "      <td>0.258947</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.424756</td>\n",
       "      <td>0.871383</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.683554</td>\n",
       "      <td>0.575287</td>\n",
       "      <td>0.639810</td>\n",
       "      <td>0.675830</td>\n",
       "      <td>0.759674</td>\n",
       "      <td>0.646018</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.785100</td>\n",
       "      <td>0.799065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978718</td>\n",
       "      <td>0.128421</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.477076</td>\n",
       "      <td>0.929260</td>\n",
       "      <td>0.751953</td>\n",
       "      <td>0.687225</td>\n",
       "      <td>0.560432</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.672394</td>\n",
       "      <td>0.759674</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.828080</td>\n",
       "      <td>0.850467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.532632</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.424067</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.703377</td>\n",
       "      <td>0.593518</td>\n",
       "      <td>0.671632</td>\n",
       "      <td>0.682703</td>\n",
       "      <td>0.792261</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>0.775701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969519</td>\n",
       "      <td>0.218947</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.508743</td>\n",
       "      <td>0.929260</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.747430</td>\n",
       "      <td>0.583390</td>\n",
       "      <td>0.685173</td>\n",
       "      <td>0.688431</td>\n",
       "      <td>0.759674</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.850467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.932456</td>\n",
       "      <td>0.604211</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.507366</td>\n",
       "      <td>0.916399</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.714391</td>\n",
       "      <td>0.675219</td>\n",
       "      <td>0.689912</td>\n",
       "      <td>0.723940</td>\n",
       "      <td>0.859470</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.715556</td>\n",
       "      <td>0.793696</td>\n",
       "      <td>0.827103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.968167</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.369682</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.654919</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>0.601219</td>\n",
       "      <td>0.568156</td>\n",
       "      <td>0.708758</td>\n",
       "      <td>0.634218</td>\n",
       "      <td>0.568889</td>\n",
       "      <td>0.736390</td>\n",
       "      <td>0.864486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.707368</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.553490</td>\n",
       "      <td>0.897106</td>\n",
       "      <td>0.798828</td>\n",
       "      <td>0.796623</td>\n",
       "      <td>0.708980</td>\n",
       "      <td>0.707515</td>\n",
       "      <td>0.682703</td>\n",
       "      <td>0.830957</td>\n",
       "      <td>0.684366</td>\n",
       "      <td>0.782222</td>\n",
       "      <td>0.819484</td>\n",
       "      <td>0.939252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.514250</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.815712</td>\n",
       "      <td>0.752870</td>\n",
       "      <td>0.688558</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.759674</td>\n",
       "      <td>0.634218</td>\n",
       "      <td>0.695556</td>\n",
       "      <td>0.779370</td>\n",
       "      <td>0.841121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.937776</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.525265</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.795154</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>0.662153</td>\n",
       "      <td>0.641466</td>\n",
       "      <td>0.847251</td>\n",
       "      <td>0.669617</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.925234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.926233</td>\n",
       "      <td>0.671579</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.571389</td>\n",
       "      <td>0.900322</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.825257</td>\n",
       "      <td>0.732613</td>\n",
       "      <td>0.725118</td>\n",
       "      <td>0.679267</td>\n",
       "      <td>0.859470</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>0.859599</td>\n",
       "      <td>0.976636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Density   BodyFat       Age    Weight    Height      Neck     Chest  \\\n",
       "0    0.965642  0.258947  0.283951  0.424756  0.871383  0.707031  0.683554   \n",
       "1    0.978718  0.128421  0.271605  0.477076  0.929260  0.751953  0.687225   \n",
       "2    0.939129  0.532632  0.271605  0.424067  0.852090  0.664062  0.703377   \n",
       "3    0.969519  0.218947  0.320988  0.508743  0.929260  0.730469  0.747430   \n",
       "4    0.932456  0.604211  0.296296  0.507366  0.916399  0.671875  0.714391   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "247  0.968167  0.231579  0.864198  0.369682  0.861736  0.681641  0.654919   \n",
       "248  0.923077  0.707368  0.888889  0.553490  0.897106  0.798828  0.796623   \n",
       "249  0.931373  0.616842  0.888889  0.514250  0.848875  0.759766  0.815712   \n",
       "250  0.937776  0.547368  0.888889  0.525265  0.906752  0.759766  0.795154   \n",
       "251  0.926233  0.671579  0.913580  0.571389  0.900322  0.796875  0.825257   \n",
       "\n",
       "      Abdomen       Hip     Thigh      Knee     Ankle    Biceps   Forearm  \\\n",
       "0    0.575287  0.639810  0.675830  0.759674  0.646018  0.711111  0.785100   \n",
       "1    0.560432  0.668246  0.672394  0.759674  0.690265  0.677778  0.828080   \n",
       "2    0.593518  0.671632  0.682703  0.792261  0.707965  0.640000  0.722063   \n",
       "3    0.583390  0.685173  0.688431  0.759674  0.672566  0.720000  0.842407   \n",
       "4    0.675219  0.689912  0.723940  0.859470  0.707965  0.715556  0.793696   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "247  0.564483  0.601219  0.568156  0.708758  0.634218  0.568889  0.736390   \n",
       "248  0.708980  0.707515  0.682703  0.830957  0.684366  0.782222  0.819484   \n",
       "249  0.752870  0.688558  0.690722  0.759674  0.634218  0.695556  0.779370   \n",
       "250  0.683997  0.662153  0.641466  0.847251  0.669617  0.677778  0.842407   \n",
       "251  0.732613  0.725118  0.679267  0.859470  0.725664  0.748889  0.859599   \n",
       "\n",
       "        Wrist  \n",
       "0    0.799065  \n",
       "1    0.850467  \n",
       "2    0.775701  \n",
       "3    0.850467  \n",
       "4    0.827103  \n",
       "..        ...  \n",
       "247  0.864486  \n",
       "248  0.939252  \n",
       "249  0.841121  \n",
       "250  0.925234  \n",
       "251  0.976636  \n",
       "\n",
       "[252 rows x 15 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df/df.max()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f24edab4-a69d-4a0d-8bb8-0f5dc259cac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.258947\n",
       "1      0.128421\n",
       "2      0.532632\n",
       "3      0.218947\n",
       "4      0.604211\n",
       "         ...   \n",
       "247    0.231579\n",
       "248    0.707368\n",
       "249    0.616842\n",
       "250    0.547368\n",
       "251    0.671579\n",
       "Name: BodyFat, Length: 252, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.pop('BodyFat')\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd00b353-a086-4f11-950c-edcaab16346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d53c920-c6f3-4643-b5b4-cdc0c71a2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = tf.convert_to_tensor(X_train)\n",
    "input_test = tf.convert_to_tensor(X_test)\n",
    "output_train = tf.convert_to_tensor(y_train)\n",
    "output_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d71e8ea-4ac8-4bac-bd48-5adcc4158a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(201, 14), dtype=float64, numpy=\n",
       "array([[0.94607268, 0.48148148, 0.45917665, ..., 0.72666667, 0.81088825,\n",
       "        0.79906542],\n",
       "       [0.94444945, 0.66666667, 0.54522924, ..., 0.79777778, 0.86532951,\n",
       "        0.88317757],\n",
       "       [0.92064208, 0.54320988, 0.61407132, ..., 0.77333333, 0.87965616,\n",
       "        0.81308411],\n",
       "       ...,\n",
       "       [0.97348724, 0.58024691, 0.45504612, ..., 0.66888889, 0.80802292,\n",
       "        0.85981308],\n",
       "       [0.95617278, 0.48148148, 0.6464271 , ..., 0.86888889, 0.93123209,\n",
       "        0.92990654],\n",
       "       [0.94958968, 0.50617284, 0.47569875, ..., 0.68888889, 0.83667622,\n",
       "        0.85981308]])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "741d033d-6d0f-4b65-9b36-f190a711c022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(input_train[0])\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ecb47714-d693-4492-b0b2-ce3c606ffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ReLU\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "                Input(shape=(num_features,)),\n",
    "                tf.keras.layers.Dense(128, activation='relu'),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(32,activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4d081ca8-d568-40b5-8157-39d3a4e92bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 128)               1920      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12289 (48.00 KB)\n",
      "Trainable params: 12289 (48.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dc101e51-5995-4986-aa80-926bab87de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean((y_true - y_pred)**2))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model.compile(optimizer=adam,loss=RMSE, metrics=RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6de10253-ec32-4a55-a11c-5173e285dcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 15ms/step - loss: 0.1949 - RMSE: 0.1953 - val_loss: 0.1431 - val_RMSE: 0.1431\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1965 - RMSE: 0.1954 - val_loss: 0.1399 - val_RMSE: 0.1399\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1901 - RMSE: 0.1921 - val_loss: 0.1346 - val_RMSE: 0.1346\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1898 - RMSE: 0.1916 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1876 - RMSE: 0.1866 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1877 - RMSE: 0.1874 - val_loss: 0.1316 - val_RMSE: 0.1316\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1872 - RMSE: 0.1872 - val_loss: 0.1301 - val_RMSE: 0.1301\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1921 - RMSE: 0.1934 - val_loss: 0.1315 - val_RMSE: 0.1315\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1979 - RMSE: 0.1976 - val_loss: 0.1313 - val_RMSE: 0.1313\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1921 - RMSE: 0.1921 - val_loss: 0.1393 - val_RMSE: 0.1393\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1874 - RMSE: 0.1866 - val_loss: 0.1446 - val_RMSE: 0.1446\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1904 - RMSE: 0.1888 - val_loss: 0.1375 - val_RMSE: 0.1375\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1952 - RMSE: 0.1959 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1891 - RMSE: 0.1904 - val_loss: 0.1309 - val_RMSE: 0.1309\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1909 - RMSE: 0.1927 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1925 - RMSE: 0.1934 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1874 - RMSE: 0.1874 - val_loss: 0.1308 - val_RMSE: 0.1308\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1887 - RMSE: 0.1870 - val_loss: 0.1318 - val_RMSE: 0.1318\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1866 - RMSE: 0.1851 - val_loss: 0.1350 - val_RMSE: 0.1350\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1983 - RMSE: 0.1968 - val_loss: 0.1308 - val_RMSE: 0.1308\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1893 - RMSE: 0.1874 - val_loss: 0.1310 - val_RMSE: 0.1310\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1872 - RMSE: 0.1880 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1891 - RMSE: 0.1867 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1895 - RMSE: 0.1922 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1867 - RMSE: 0.1852 - val_loss: 0.1309 - val_RMSE: 0.1309\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1876 - RMSE: 0.1872 - val_loss: 0.1302 - val_RMSE: 0.1302\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1877 - RMSE: 0.1872 - val_loss: 0.1312 - val_RMSE: 0.1312\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1890 - RMSE: 0.1901 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1891 - RMSE: 0.1887 - val_loss: 0.1317 - val_RMSE: 0.1317\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1900 - RMSE: 0.1903 - val_loss: 0.1308 - val_RMSE: 0.1308\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1888 - RMSE: 0.1876 - val_loss: 0.1316 - val_RMSE: 0.1316\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1872 - RMSE: 0.1884 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1885 - RMSE: 0.1860 - val_loss: 0.1301 - val_RMSE: 0.1301\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1898 - RMSE: 0.1891 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1875 - RMSE: 0.1893 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1879 - RMSE: 0.1893 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1885 - RMSE: 0.1874 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1867 - RMSE: 0.1863 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1881 - RMSE: 0.1869 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1900 - RMSE: 0.1912 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1956 - RMSE: 0.1981 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1987 - RMSE: 0.1997 - val_loss: 0.1312 - val_RMSE: 0.1312\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2014 - RMSE: 0.2018 - val_loss: 0.1314 - val_RMSE: 0.1314\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1947 - RMSE: 0.1971 - val_loss: 0.1342 - val_RMSE: 0.1342\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1956 - RMSE: 0.1944 - val_loss: 0.1406 - val_RMSE: 0.1406\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1932 - RMSE: 0.1913 - val_loss: 0.1370 - val_RMSE: 0.1370\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1892 - RMSE: 0.1891 - val_loss: 0.1363 - val_RMSE: 0.1363\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1899 - RMSE: 0.1881 - val_loss: 0.1325 - val_RMSE: 0.1325\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1879 - RMSE: 0.1876 - val_loss: 0.1321 - val_RMSE: 0.1321\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1890 - RMSE: 0.1879 - val_loss: 0.1302 - val_RMSE: 0.1302\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1869 - RMSE: 0.1847 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1875 - RMSE: 0.1867 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1876 - RMSE: 0.1873 - val_loss: 0.1302 - val_RMSE: 0.1302\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1860 - RMSE: 0.1890 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1874 - RMSE: 0.1856 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1895 - RMSE: 0.1899 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1899 - RMSE: 0.1910 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1866 - RMSE: 0.1852 - val_loss: 0.1306 - val_RMSE: 0.1306\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1899 - RMSE: 0.1907 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1884 - RMSE: 0.1887 - val_loss: 0.1304 - val_RMSE: 0.1304\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1884 - RMSE: 0.1871 - val_loss: 0.1303 - val_RMSE: 0.1303\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1872 - RMSE: 0.1918 - val_loss: 0.1308 - val_RMSE: 0.1308\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1878 - RMSE: 0.1921 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1874 - RMSE: 0.1887 - val_loss: 0.1316 - val_RMSE: 0.1316\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1883 - RMSE: 0.1897 - val_loss: 0.1303 - val_RMSE: 0.1303\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1912 - RMSE: 0.1899 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1877 - RMSE: 0.1883 - val_loss: 0.1313 - val_RMSE: 0.1313\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1940 - RMSE: 0.1933 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1906 - RMSE: 0.1890 - val_loss: 0.1309 - val_RMSE: 0.1309\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1879 - RMSE: 0.1876 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1909 - RMSE: 0.1909 - val_loss: 0.1303 - val_RMSE: 0.1303\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1884 - RMSE: 0.1883 - val_loss: 0.1307 - val_RMSE: 0.1307\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1877 - RMSE: 0.1900 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1867 - RMSE: 0.1892 - val_loss: 0.1303 - val_RMSE: 0.1303\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1905 - RMSE: 0.1905 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1878 - RMSE: 0.1862 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1877 - RMSE: 0.1905 - val_loss: 0.1313 - val_RMSE: 0.1313\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1880 - RMSE: 0.1862 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1961 - RMSE: 0.1951 - val_loss: 0.1300 - val_RMSE: 0.1300\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1892 - RMSE: 0.1893 - val_loss: 0.1302 - val_RMSE: 0.1302\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1903 - RMSE: 0.1901 - val_loss: 0.1312 - val_RMSE: 0.1312\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1887 - RMSE: 0.1889 - val_loss: 0.1316 - val_RMSE: 0.1316\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1858 - RMSE: 0.1857 - val_loss: 0.1358 - val_RMSE: 0.1358\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1902 - RMSE: 0.1872 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1877 - RMSE: 0.1891 - val_loss: 0.1313 - val_RMSE: 0.1313\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1877 - RMSE: 0.1888 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1878 - RMSE: 0.1916 - val_loss: 0.1317 - val_RMSE: 0.1317\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1880 - RMSE: 0.1890 - val_loss: 0.1304 - val_RMSE: 0.1304\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1899 - RMSE: 0.1901 - val_loss: 0.1335 - val_RMSE: 0.1335\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1895 - RMSE: 0.1889 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1886 - RMSE: 0.1867 - val_loss: 0.1304 - val_RMSE: 0.1304\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1889 - RMSE: 0.1870 - val_loss: 0.1298 - val_RMSE: 0.1298\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1904 - RMSE: 0.1923 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1893 - RMSE: 0.1858 - val_loss: 0.1306 - val_RMSE: 0.1306\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1877 - RMSE: 0.1869 - val_loss: 0.1307 - val_RMSE: 0.1307\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1886 - RMSE: 0.1845 - val_loss: 0.1299 - val_RMSE: 0.1299\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1911 - RMSE: 0.1899 - val_loss: 0.1305 - val_RMSE: 0.1305\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1905 - RMSE: 0.1909 - val_loss: 0.1309 - val_RMSE: 0.1309\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1921 - RMSE: 0.1900 - val_loss: 0.1302 - val_RMSE: 0.1302\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1906 - RMSE: 0.1906 - val_loss: 0.1299 - val_RMSE: 0.1299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f40e01d25d0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "model.fit(input_train, output_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9642498d-b596-4f6a-96c9-98725dad990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1460 - RMSE: 0.1491\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(input_test, output_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39d6d3bc-bbfa-4963-904c-135692616b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.14598232507705688\n",
      "Test Accuracy: 0.14912056922912598\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb986927-9d6b-4802-bbba-0e40119a69a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in ./anaconda3/envs/dse/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in ./anaconda3/envs/dse/lib/python3.11/site-packages (from pydot) (3.0.9)\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pydot\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6d1a8c7d-d177-4b59-b4a5-0e4b84e6a441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(201, 1), dtype=float32, numpy=\n",
       "array([[0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405],\n",
       "       [0.40842405]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77867151-4bc1-491a-adee-e9473cc277e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
